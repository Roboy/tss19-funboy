% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Conclusion}\label{chapter:conclusion}

The aim of the thesis was to explore how people react to jokes produced by a Neural Language Model conditioned on humour data and delivered by a robot in verbal interaction. We had to develop the DARVAH loop and implement it in the Funboy module for Ravestate, our Dialogue System, to be able to produce humorous utterances when needed. We achieved the humour generation capabilities by utilising Transfer Learning on the state-of-the-art GPT-2-L Language Model to condition it on the humour data using over 600 000 jokes that we collected using online sources, mainly Reddit forums. Besides the humour generation capabilities, it was necessary to implement the emotion recognition functionality for our robot. To accomplish this task, we employed EmoPy and \acrfull{ser} software packages which we had to adapt to our system architecture such as ROS 1.0 interfaces, Docker deployment and background processing. We combined these to parts together to form a feedback loop for the DARVAH generation, evaluation and adjustment. To store the information about interlocutors' affinity scores, we used ScientIO combined with Neo4j.  

Using the implemented modules, we conducted the experiment to observe the participants behaviour. The respondents have also answered questionnaires to provide their self-assessment on the experiment. We obtained and investigated both automatic emotion recognition and self-assessment results to answer how people react to joking robots. The main conclusion is that the people were mainly confused and frustrated due to several reasons:

\begin{itemize}
    \item Considerable delays between the input and the output because of the high computation cost of running GPT-2 models.  
    \item Disfluencies, lexical noise and non-jokes in the humour generation results. Semantically unrelated responses both from Ravestate Funboy and Wildtalk modules.
    \item The Ravestate Wildtalk module that acted as a non-humorous alternative provides only a small range of answers and is not deterministic.  
    \item Imperfect Automatic Speech Recognition which suffers from accents and background noise.
\end{itemize}

However, the participants also found the whole situation, when the robot tries to joke, funny and endorsed the idea. 

To simplify current and future development, we divided the system into separate parts integrated via ROS and web-socket interfaces. The modules of the system can act independently:

\begin{itemize}
    \item Funboy is a Ravestate module that implements the main loop of the DARVAH framework and supports the humour generation and evaluation capabilities. The module comprises functionally independent states that support common signals-and-conditions interface. The internal implementation of each state is subject to any possible improvements in the future:
    \begin{itemize}
        \item Deduce state - decides if the current conversation requires a humorous response.
        \item Assess state - retrieves interlocutor's data and selects humour types based on their affinity scores.
        \item Render state - using the chosen humour types, generates a proactive or reactive humorous response.
        \item Validate state - receives and evaluates emotion scores vectors from Rosemo. 
        \item Attune state - based on the emotions evaluation, adjusts the affinity scores for the humour types.
    \end{itemize}
    \item GPT-2 TLH - is a GPT-2-based \acrshort{dnn} Language Model conditioned on humour data that generates jokes based on passed joke types. It is also deployable as a standalone server.
    \item Funboyn4j - is a Docker container that contains Neo4j graph database storing the affinity scores of interlocutors and other Ravestate data.
    \item Rosemo is an emotion recognition module that contains two packages for image and audio emotion recognition. The module supports ROS 1.0 interfaces and Docker deployment.
\end{itemize}

We have also developed an additional software package that creates a Telegram bot that we can use in the future to allow people to score jokes generated by GPT-2 TLH. In the future, this information can help us to not only create a more advanced approach to the assessment and the attuning processes in the DARVAH framework but also to create a more advanced Humour Language Model on top of the existing one. 

Although the humour generation and emotion recognition tasks did not fully demonstrate their potential at the current state of both technologies, they successfully showed their prospects as proof of concept. The experiment and the obtained results (in Chapter \ref{chapter:experiment}) demonstrated that it is possible to develop a Dialogue System that can tackle humour generation and adaptation problems at a satisfactory level given the state-of-the-art in Natural Language Processing. 

Therefore, we see potential in developing the project further by addressing the challenges and solving the problems stated in Chapter \ref{chapter:challenges} as well as taking the research to the next level considering our proposals. The future advances in humour applications in Dialogue Systems may uncover great opportunities to improve verbal Human-Robot Interaction.
@book{latex,
    title = {LaTeX : A Documentation Preparation System User's Guide and Reference Manual},
    publisher = {Addison-Wesley Professional},
    year = {1994},
    author = {Leslie Lamport}
}

@inproceedings{10.1145/3242969.3242976,
    author = {Weber, Klaus and Ritschel, Hannes and Aslan, Ilhan and Lingenfelser, Florian and Andr\'{e}, Elisabeth},
    title = {How to Shape the Humor of a Robot - Social Behavior Adaptation Based on Reinforcement Learning},
    year = {2018},
    isbn = {9781450356923},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3242969.3242976},
    doi = {10.1145/3242969.3242976},
    booktitle = {Proceedings of the 20th ACM International Conference on Multimodal Interaction},
    pages = {154–162},
    numpages = {9},
    keywords = {human-robot-interaction, social adaptation, socially-aware agents},
    location = {Boulder, CO, USA},
    series = {ICMI ’18}
}

@inproceedings{ritschel-andre-2018-shaping,
    title = "Shaping a social robot{'}s humor with Natural Language Generation and socially-aware reinforcement learning",
    author = "Ritschel, Hannes  and
      Andr{\'e}, Elisabeth",
    booktitle = "Proceedings of the Workshop on {NLG} for Human{--}Robot Interaction",
    month = nov,
    year = "2018",
    address = "Tilburg, The Netherlands",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-6903",
    doi = "10.18653/v1/W18-6903",
    pages = "12--16",
    abstract = "Humor is an important aspect in human interaction to regulate conversations, increase interpersonal attraction and trust. For social robots, humor is one aspect to make interactions more natural, enjoyable, and to increase credibility and acceptance. In combination with appropriate non-verbal behavior, natural language generation offers the ability to create content on-the-fly. This work outlines the building-blocks for providing an individual, multimodal interaction experience by shaping the robot{'}s humor with the help of Natural Language Generation and Reinforcement Learning based on human social signals.",
}

@article{radford2019language,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}

@online{gpt2,
  author = {OpenAI},
  title = {gpt-2},
  note = {GitHub Repository},
  year = 2019,
  url = {https://github.com/openai/gpt-2},
  urldate = {2020-03-12}
}

@inproceedings{BarsoumICMI2016,
    title={Training Deep Networks for Facial Expression Recognition with Crowd-Sourced Label Distribution},
    author={Barsoum, Emad and Zhang, Cha and Canton Ferrer, Cristian and Zhang, Zhengyou},
    booktitle={ACM International Conference on Multimodal Interaction (ICMI)},
    year={2016}
}

@misc{baumgartner2020pushshift,
    title={The Pushshift Reddit Dataset},
    author={Jason Baumgartner and Savvas Zannettou and Brian Keegan and Megan Squire and Jeremy Blackburn},
    year={2020},
    eprint={2001.08435},
    archivePrefix={arXiv},
    primaryClass={cs.SI}
}

@online{gpt2simple,
  author = {Max Woolf},
  title = {gpt-2-simple},
  note = {GitHub Repository},
  year = 2019,
  url = {https://github.com/minimaxir/gpt-2-simple},
  urldate = {2020-03-12}
}

@online{maelmer,
  author = {Maël Fabien},
  title = {Multimodal-Emotion-Recognition},
  note = {GitHub Repository},
  year = 2019,
  url = {https://github.com/maelfabien/Multimodal-Emotion-Recognition},
  urldate = {2020-03-12}
}

@online{pungas,
    title={A dataset of English plaintext jokes.},
    url={https://github.com/taivop/joke-dataset},
    author={Pungas, Taivo},
    year={2017},
    note = {GitHub Repository},
    urldate = {2020-03-12}
}

@online{emopygh,
    title={EmoPy},
    url={https://github.com/thoughtworksarts/EmoPy},
    author={ThoughtWorks Arts},
    year={2018},
    note = {GitHub Repository},
    urldate = {2020-03-12}
}

@online{emopy,
    title={EmoPy: a machine learning toolkit for emotional expression},
    url={https://www.thoughtworks.com/insights/blog/emopy-machine-learning-toolkit-emotional-expression},
    author={Perez, Angelica},
    year={2018},
    note = {ThoughtWorks},
    urldate = {2020-03-12}
}

@online{transferlearn,
    title={Transfer Learning},
    url={http://ftp.cs.wisc.edu/machine-learning/shavlik-group/torrey.handbook09.pdf},
    author={Torrey, Lisa and Shavlik, Jude},
    year={2009},
    note = {University of Wisconsin},
    urldate = {2020-03-12}
}

@online{ravestate,
    title={Ravestate},
    url={https://roboy.github.io/ravestate/},
    author={Roboy},
    year={2019},
    note = {GitHub Repository},
    urldate = {2020-03-12}
}

@online{rele,
    title={Reinforcement Learning: An Introduction},
    url={http://incompleteideas.net/book/RLbook2018.pdf},
    author={Richard S. Sutton and Andrew G. Barto},
    year={2018},
    publisher={MIT Press},
    urldate = {2020-03-12}
}

@inproceedings{Radford2018ImprovingLU,
  title={Improving Language Understanding by Generative Pre-Training},
  author={Alec Radford},
  year={2018}
}

@dataset{livingstone_steven_r_2018_1188976,
  author       = {Livingstone, Steven R. and
                  Russo, Frank A.},
  title        = {{The Ryerson Audio-Visual Database of Emotional 
                   Speech and Song (RAVDESS)}},
  month        = apr,
  year         = 2018,
  note         = {{Funding Information Natural Sciences and 
                   Engineering Research Council of Canada:
                   2012-341583  Hear the world research chair in
                   music and emotional speech from Phonak}},
  publisher    = {Zenodo},
  version      = {1.0.0},
  doi          = {10.5281/zenodo.1188976},
  url          = {https://doi.org/10.5281/zenodo.1188976}
}


@inbook{cb48d59358674187a9fccbc31a3bbd51,
title = "Conversational Agents and the Construction of Humorous Acts",
abstract = "In this chapter we discuss the generation of humorous acts by embodied agents. It is observed that in future interfaces that are meant to allow natural interaction, embodied agents can play useful roles. Humor plays an important role in human-human interaction and therefore it is useful to investigate how it should become part of the internal modeling of an embodied agent, along with intelligence and emotion modeling. Employment of embodied agents will also give rise to expectations concerning intelligence, emotions and humor. We adhere to the ‘Computers Are Social Actors’ paradigm to assume that human conversational partners of embodied conversational agents assign human properties to these agents, including humor generation and appreciation. In this chapter we discuss how an embodied agent can construct a humorous act from the discourse and when it should be displayed. As an example, we zoom in on erroneous anaphora resolution. Moreover, we have some preliminary observations on the nonverbal aspects of humor generation and appreciation by an embodied agent. This chapter presents only a modest step towards the use of humor in an interface employing an embodied agent. Rather than being able to introduce algorithms for humorous act production we discuss the issues that are involved. From our observations it becomes clear that current research on affective computing, research on generating and interpreting facial expressions and research on embodied (and intelligent) agents can and should be combined with humor research. This is not only for the benefit of humor research, since results can help to design new and interesting applications in human-computer interaction using embodied agents in general.",
keywords = "HMI-MI: MULTIMODAL INTERACTIONS, EWI-10318, IR-61759, METIS-242177, EC Grant Agreement nr.: FP5/30039",
author = "Antinus Nijholt",
note = "10.1002/9780470512470.ch2",
year = "2007",
month = "11",
day = "1",
doi = "10.1002/9780470512470.ch2",
language = "Undefined",
isbn = "978-0-470-02699-1",
publisher = "Wiley",
number = "P2773",
pages = "21--47",
editor = "Toyoaki Nishida",
booktitle = "Conversational Informatics: An Engineering Approach",
address = "United States",

}

@misc{binsted1994symbolic,
    title={A symbolic description of punning riddles and its computer implementation},
    author={Kim Binsted and Graeme Ritchie},
    year={1994},
    eprint={cmp-lg/9406021},
    archivePrefix={arXiv},
    primaryClass={cmp-lg}
}


@inproceedings{3ae3f943de704b378c6f53fd1f0d358a,
title = "A practical application of computational humour",
abstract = "The past 15 years has seen the development of a number of programs which perform tasks in the area of humour, but these have been exploratory research prototypes, usually on a very small scale, and none of them interacted with users. Amongst those which actually created humorous texts, the JAPE program was probably the most substantial, but even it was far from being useful for any practical purpose. We have developed a fully engineered riddle generator, inspired by the ideas in the JAPE system, which uses a large-scale multimedia lexicon and a set of symbolic rules to generate jokes. It has an interactive user interface, specially designed for children with complex communication needs (CCN), so that users can make choices to guide the riddle generator. The software is robust, stable, and responds sufficiently promptly that naive users can interact without difficulty. It has been tested over with real users (children with CCN), with highly positive results, and is publicly available for free download.",
keywords = "computational humour, riddles, joke generation, AAC",
author = "Ritchie, {Graeme D} and Ruli Manurung and Helen Pain and Annalu Waller and Rolf Black and Dave O'Mara",
year = "2007",
language = "English",
pages = "91--98",
editor = "Amilcar Cardoso and Wiggins, {Geraint A.}",
booktitle = "Proceedings of the Fourth International Joint Conference on Computational Creativity (Goldsmith's, London)",

}



@paper{IJCAI136900,
	author = {Rolf Pfeifer and Hugo Marques and Fumiya Iida},
	title = {Soft Robotics: The Next Generation of Intelligent Machines},
	conference = {International Joint Conference on Artificial Intelligence},
	year = {2013},
	keywords = {robotics, soft robotics, intelligent machines, artificial intelligence},
	abstract = {There has been an increasing interest in applying biological principles to the design and control of robots. Unlike industrial robots that are programmed to execute a rather limited number of tasks, the new generation of bio-inspired robots is expected to display a wide range of behaviours in unpredictable environments, as well as to interact safely and smoothly with human co-workers. In this article, we put forward some of the properties that will characterize these new robots: soft materials, flexible and stretchable sensors, modular and efficient actuators, self-organization and distributed control. We introduce a number of design principles; in particular, we try to comprehend the novel design space that now includes soft materials and requires a completely different way of thinking about control. We also introduce a recent case study of developing a complex humanoid robot, discuss the lessons learned and speculate about future challenges and perspectives. 1},
}

@inproceedings{cardsflow,
author = {Trendel, Simon and Chan, Yin and Kharchenko, Alona and Hostettler, Rafael and Knoll, Alois and Lau, Darwin},
year = {2018},
month = {11},
pages = {245-250},
title = {CARDSFlow: An End-to-End Open-Source Physics Environment for the Design, Simulation and Control of Musculoskeletal Robots},
doi = {10.1109/HUMANOIDS.2018.8624940}
}

